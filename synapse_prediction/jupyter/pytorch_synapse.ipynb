{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML, Image\n",
    "from ipywidgets import interact,Dropdown,IntSlider,FloatRangeSlider, FloatSlider, RadioButtons\n",
    "rc('animation', html='html5')\n",
    "import gc, argparse, sys, os, errno\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from beakerx import *\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import h5py\n",
    "import os,sys\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xupeng/projects/synapse\n"
     ]
    }
   ],
   "source": [
    "cd /home/xupeng/projects/synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('bin/synapse_pytorch-master/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, h5py, time, argparse, itertools, datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from libs import SynapseDataset, collate_fn, WeightedBCELoss, res_unet\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nif __name__ == \"__main__\":\\n    main()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Synapse Detection Model')\n",
    "    # I/O\n",
    "    parser.add_argument('-t','--train',  default='data/cremi/',\n",
    "                        help='Input folder (train)')\n",
    "    # parser.add_argument('-v','--val',  default='',\n",
    "    #                     help='input folder (test)')\n",
    "    parser.add_argument('-dn','--img-name',  default='images/im_A_v2_200.h5',\n",
    "                        help='Image data path')\n",
    "    parser.add_argument('-ln','--seg-name',  default='gt-syn/syn_A_v2_200.h5',\n",
    "                        help='Ground-truth label path')\n",
    "    parser.add_argument('-o','--output', default='result/train/',\n",
    "                        help='Output path')\n",
    "    parser.add_argument('-mi','--model-input', type=str,  default='31,204,204',\n",
    "                        help='I/O size of deep network')\n",
    "    parser.add_argument('-ft','--finetune', default=False,\n",
    "                        help='Fine-tune on previous model [Default: False]')\n",
    "    parser.add_argument('-pm','--pre-model', type=str, default='',\n",
    "                        help='Pre-trained model path')                  \n",
    "\n",
    "    # optimization option\n",
    "    parser.add_argument('-lr', type=float, default=0.0001,\n",
    "                        help='Learning rate')\n",
    "    # parser.add_argument('-lr_decay', default='inv,0.0001,0.75',\n",
    "    #                     help='learning rate decay')\n",
    "    # parser.add_argument('-betas', default='0.99,0.999',\n",
    "    #                     help='beta for adam')\n",
    "    # parser.add_argument('-wd', type=float, default=5e-6,\n",
    "    #                     help='weight decay')\n",
    "    parser.add_argument('--volume-total', type=int, default=1000,\n",
    "                        help='Total number of iteration')\n",
    "    parser.add_argument('--volume-save', type=int, default=100,\n",
    "                        help='Number of iteration to save')\n",
    "    parser.add_argument('-g','--num-gpu', type=int,  default=1,\n",
    "                        help='Number of gpu')\n",
    "    parser.add_argument('-c','--num-cpu', type=int,  default=1,\n",
    "                        help='Number of cpu')\n",
    "    parser.add_argument('-b','--batch-size', type=int,  default=1,\n",
    "                        help='Batch size')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def init(args):\n",
    "    sn = args.output+'/'\n",
    "    if not os.path.isdir(sn):\n",
    "        os.makedirs(sn)\n",
    "    # I/O size in (z,y,x), no specified channel number\n",
    "    model_io_size = np.array([int(x) for x in args.model_input.split(',')])\n",
    "\n",
    "    # select training machine\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return model_io_size, device\n",
    "\n",
    "def get_input(args, model_io_size, opt='train'):\n",
    "    # two dataLoader, can't be both multiple-cpu (pytorch issue)\n",
    "\n",
    "    if opt=='train':\n",
    "        dir_name = args.train.split('@')\n",
    "        num_worker = args.num_cpu\n",
    "        img_name = args.img_name.split('@')\n",
    "        seg_name = args.seg_name.split('@')\n",
    "    else:\n",
    "        dir_name = args.val.split('@')\n",
    "        num_worker = 1\n",
    "        img_name = args.img_name_val.split('@')\n",
    "        seg_name = args.seg_name_val.split('@')\n",
    "\n",
    "    # may use datasets from multiple folders\n",
    "    # should be either one or the same as dir_name\n",
    "    seg_name = [dir_name[0] + x for x in seg_name]\n",
    "    img_name = [dir_name[0] + x for x in img_name]\n",
    "    # print(img_name)\n",
    "    # print(seg_name)\n",
    "    \n",
    "    # 1. load data\n",
    "    train_input = [None]*len(img_name)\n",
    "    train_label = [None]*len(seg_name)\n",
    "    assert len(img_name)==len(seg_name)\n",
    "\n",
    "    # original image is in [0, 255], normalize to [0, 1]\n",
    "    for i in range(len(img_name)):\n",
    "        train_input[i] = np.array(h5py.File(img_name[i], 'r')['main'])[14:-14, 200:-200, 200:-200]/255.0\n",
    "        train_label[i] = np.array(h5py.File(seg_name[i], 'r')['main'])[14:-14, 200:-200, 200:-200]\n",
    "        train_label[i] = (train_label[i] != 0).astype(float)\n",
    "        assert train_input[i].shape==train_label[i].shape\n",
    "        print(\"volume shape: \", train_input[i].shape)    \n",
    "\n",
    "    dataset = SynapseDataset(volume=train_input, label=train_label, vol_input_size=model_io_size, \\\n",
    "                                 vol_label_size=model_io_size, data_aug=None) # no data augmentation\n",
    "    # to have evaluation during training (two dataloader), has to set num_worker=0\n",
    "    SHUFFLE = (opt=='train')\n",
    "    img_loader =  torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=args.batch_size, shuffle=SHUFFLE, collate_fn = collate_fn,\n",
    "            num_workers=args.num_cpu, pin_memory=True)\n",
    "    return img_loader\n",
    "\n",
    "def get_logger(args):\n",
    "    log_name = args.output+'/log'\n",
    "    date = str(datetime.datetime.now()).split(' ')[0]\n",
    "    time = str(datetime.datetime.now()).split(' ')[1].split('.')[0]\n",
    "    log_name += '_approx_'+date+'_'+time\n",
    "    logger = open(log_name+'.txt','w') # unbuffered, write instantly\n",
    "\n",
    "    # tensorboardX\n",
    "    writer = SummaryWriter('runs/'+log_name)\n",
    "    return logger, writer\n",
    "\n",
    "def train(args, train_loader, model, device, criterion, optimizer, logger, writer):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    volume_id = 0\n",
    "\n",
    "    for i, (volume, label, class_weight, weight_factor) in enumerate(train_loader):\n",
    "        volume_id += args.batch_size\n",
    "\n",
    "        # for gpu computing\n",
    "        print(weight_factor)\n",
    "        volume, label = volume.to(device), label.to(device)\n",
    "        class_weight = class_weight.to(device)\n",
    "        output = model(volume)\n",
    "        loss = criterion(output, label, class_weight)\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logger.write(\"[Volume %d] train_loss=%0.4f lr=%.5f\" % (volume_id, \\\n",
    "                loss.item(), optimizer.param_groups[0]['lr']))\n",
    "        writer.add_scalar('train_loss', loss.item(), volume_id)\n",
    "\n",
    "        # LR update\n",
    "        #if args.lr > 0:\n",
    "            #decay_lr(optimizer, args.lr, volume_id, lr_decay[0], lr_decay[1], lr_decay[2])\n",
    "        \n",
    "        if volume_id % args.volume_save < args.batch_size or volume_id >= args.volume_total:\n",
    "            torch.save(model.state_dict(), args.output+('/volume_%d.pth' % (volume_id)))\n",
    "        # Terminate\n",
    "        if volume_id >= args.volume_total:\n",
    "            break    #     \n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "\n",
    "    print('0. initial setup')\n",
    "    model_io_size, device = init(args) \n",
    "    logger, writer = get_logger(args)\n",
    "\n",
    "    print('1. setup data')\n",
    "    train_loader = get_input(args, model_io_size, 'train')\n",
    "\n",
    "    print('2. setup model')\n",
    "    model = res_unet()\n",
    "    if args.finetune == True:\n",
    "        model.load_state_dict(torch.load(args.pre_model))\n",
    "        print('fine-tune on previous model')\n",
    "            \n",
    "    if args.num_gpu>1: model = nn.DataParallel(model, range(args.num_gpu))\n",
    "    model = model.to(device)\n",
    "    criterion = WeightedBCELoss()\n",
    "\n",
    "    print('3. setup optimizer')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "\n",
    "    print('4. start training')\n",
    "    train(args, train_loader, model, device, criterion, optimizer, logger, writer)\n",
    "  \n",
    "    print('5. finish training')\n",
    "    logger.close()\n",
    "    writer.close()\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "model_io_size, device = init(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31 204 204]\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print (model_io_size)\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger, writer = get_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volume shape:  (125, 1442, 1327)\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_input(args, model_io_size, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe11a828ef0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = res_unet()\n",
    "#if args.finetune == True:\n",
    "#need pretrained model!\n",
    "#model.load_state_dict(torch.load(args.pre_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if args.num_gpu>1: \n",
    "model = nn.DataParallel(model, range(args.num_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = WeightedBCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e-04]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (25) must match the size of tensor b (24) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a0d3dbb9b4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-db8dba08963f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_loader, model, device, criterion, optimizer, logger, writer)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/synapse/bin/synapse_pytorch-master/libs/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (25) must match the size of tensor b (24) at non-singleton dimension 4"
     ]
    }
   ],
   "source": [
    "train(args, train_loader, model, device, criterion, optimizer, logger, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
