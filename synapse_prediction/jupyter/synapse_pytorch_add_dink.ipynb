{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import gc, argparse, sys, os, errno\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chenxupeng/projects/connect\n"
     ]
    }
   ],
   "source": [
    "cd /home/chenxupeng/projects/connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sys.path.append('bin')\n",
    "sys.path.append('bin/synapse_pytorch-master')\n",
    "from libs import SynapseDataset, collate_fn, WeightedBCELoss, res_unet\n",
    "#sys.path.append('bin/synapse_pytorch-master/libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class res_unet_IsoBlock(nn.Module):\n",
    "    # Basic residual module of unet\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(res_unet_IsoBlock, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv3d(in_planes,  out_planes, kernel_size=(3,3,3), stride=1, padding=(1,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv3d(out_planes, out_planes, kernel_size=(3,3,3), stride=1, padding=(1,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_planes, out_planes, kernel_size=(3,3,3), stride=1, padding=(1,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes))\n",
    "        self.block3 = nn.ReLU(inplace=True)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual  = self.block1(x)\n",
    "        out = residual + self.block2(residual)\n",
    "        out = self.block3(out)\n",
    "        return out \n",
    "\n",
    "class res_unet_AnisoBlock(nn.Module):\n",
    "    # Basic residual module of unet\n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        super(res_unet_AnisoBlock, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv3d(in_planes,  out_planes, kernel_size=(1,3,3), stride=1, padding=(0,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv3d(out_planes, out_planes, kernel_size=(1,3,3), stride=1, padding=(0,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_planes, out_planes, kernel_size=(1,3,3), stride=1, padding=(0,1,1), bias=False),\n",
    "            nn.BatchNorm3d(out_planes))\n",
    "        self.block3 = nn.ReLU(inplace=True)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        residual  = self.block1(x)\n",
    "        out = residual + self.block2(residual)\n",
    "        out = self.block3(out)\n",
    "        return out     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class res_unet(nn.Module):\n",
    "    # unet architecture with residual blocks\n",
    "    def __init__(self, in_num=1, out_num=1, filters=[32,64,96,128,160]):\n",
    "        super(res_unet, self).__init__()\n",
    "        self.filters = filters \n",
    "        self.layer_num = len(filters) # 5\n",
    "        self.aniso_num = 3 # the number of anisotropic conv layers\n",
    "\n",
    "        self.downC = nn.ModuleList(\n",
    "                  [res_unet_AnisoBlock(in_num, filters[0])]\n",
    "                + [res_unet_AnisoBlock(filters[x], filters[x+1])\n",
    "                      for x in range(self.aniso_num-1)] \n",
    "                + [res_unet_IsoBlock(filters[x], filters[x+1])\n",
    "                      for x in range(self.aniso_num-1, self.layer_num-2)]) \n",
    "\n",
    "        self.downS = nn.ModuleList(\n",
    "                [nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
    "                    for x in range(self.aniso_num)]\n",
    "              + [nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))\n",
    "                    for x in range(self.aniso_num, self.layer_num-1)])\n",
    "\n",
    "        self.center = res_unet_IsoBlock(filters[-2], filters[-1])\n",
    "\n",
    "        self.upS = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(2,2,2), mode='trilinear', align_corners=False),\n",
    "                nn.Conv3d(filters[self.layer_num-1-x], filters[self.layer_num-2-x], kernel_size=(3,3,3), stride=1, padding=(1,1,1), bias=True))\n",
    "                for x in range(self.layer_num-self.aniso_num-1)]\n",
    "          + [nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=False),\n",
    "                nn.Conv3d(filters[self.layer_num-1-x], filters[self.layer_num-2-x], kernel_size=(1,3,3), stride=1, padding=(0,1,1), bias=True))\n",
    "                for x in range(1, self.aniso_num+1)])\n",
    "\n",
    "        self.upC = nn.ModuleList(\n",
    "            [res_unet_IsoBlock(filters[self.layer_num-2-x], filters[self.layer_num-2-x])\n",
    "                for x in range(self.layer_num-self.aniso_num-1)]\n",
    "          + [res_unet_AnisoBlock(filters[self.layer_num-2-x], filters[self.layer_num-2-x])\n",
    "                for x in range(1, self.aniso_num)]\n",
    "          + [nn.Sequential(\n",
    "                  res_unet_AnisoBlock(filters[0], filters[0]),\n",
    "                  nn.Conv3d(filters[0], out_num, kernel_size=(1,3,3), stride=1, padding=(0,1,1), bias=True))])\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0) \n",
    "\n",
    "    def forward(self, x):\n",
    "        down_u = [None]*(self.layer_num-1)\n",
    "        for i in range(self.layer_num-1):\n",
    "            down_u[i] = self.downC[i](x)\n",
    "            x = self.downS[i](down_u[i])\n",
    "\n",
    "        x = self.center(x)\n",
    "\n",
    "        for i in range(self.layer_num-1):\n",
    "            x = down_u[self.layer_num-2-i] + self.upS[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.upC[i](x)\n",
    "            x = F.sigmoid(x)\n",
    "        return x        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "#device = torch.device('cpu')\n",
    "model = res_unet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res_unet(\n",
       "  (downC): ModuleList(\n",
       "    (0): res_unet_AnisoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (1): res_unet_AnisoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(32, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (2): res_unet_AnisoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(64, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (3): res_unet_IsoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (downS): ModuleList(\n",
       "    (0): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (center): res_unet_IsoBlock(\n",
       "    (block1): Sequential(\n",
       "      (0): Conv3d(128, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (4): BatchNorm3d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (block3): ReLU(inplace)\n",
       "  )\n",
       "  (upS): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Upsample(scale_factor=(2, 2, 2), mode=trilinear)\n",
       "      (1): Conv3d(160, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Upsample(scale_factor=(1, 2, 2), mode=trilinear)\n",
       "      (1): Conv3d(128, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Upsample(scale_factor=(1, 2, 2), mode=trilinear)\n",
       "      (1): Conv3d(96, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Upsample(scale_factor=(1, 2, 2), mode=trilinear)\n",
       "      (1): Conv3d(64, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (upC): ModuleList(\n",
       "    (0): res_unet_IsoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (1): res_unet_AnisoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (2): res_unet_AnisoBlock(\n",
       "      (block1): Sequential(\n",
       "        (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "      )\n",
       "      (block2): Sequential(\n",
       "        (0): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block3): ReLU(inplace)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): res_unet_AnisoBlock(\n",
       "        (block1): Sequential(\n",
       "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "        (block2): Sequential(\n",
       "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "          (3): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "          (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block3): ReLU(inplace)\n",
       "      )\n",
       "      (1): Conv3d(32, 1, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "summary(model,( 1,28,40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Training Synapse Detection Model')\n",
    "    # I/O\n",
    "    parser.add_argument('-t','--train',  default='data/',\n",
    "                        help='Input folder (train)')\n",
    "    # parser.add_argument('-v','--val',  default='',\n",
    "    #                     help='input folder (test)')\n",
    "    parser.add_argument('-dn','--img-name',  default='im_uint8.h5',\n",
    "                        help='Image data path')\n",
    "    parser.add_argument('-ln','--seg-name',  default='seg-groundtruth2-malis.h5',\n",
    "                        help='Ground-truth label path')\n",
    "    parser.add_argument('-o','--output', default='result/train/',\n",
    "                        help='Output path')\n",
    "    parser.add_argument('-mi','--model-input', type=str,  default='31,204,204',\n",
    "                        help='I/O size of deep network')\n",
    "    parser.add_argument('-ft','--finetune', default=False,\n",
    "                        help='Fine-tune on previous model [Default: False]')\n",
    "    parser.add_argument('-pm','--pre-model', type=str, default='',\n",
    "                        help='Pre-trained model path')                  \n",
    "\n",
    "    # optimization option\n",
    "    parser.add_argument('-lr', type=float, default=0.0001,\n",
    "                        help='Learning rate')\n",
    "    # parser.add_argument('-lr_decay', default='inv,0.0001,0.75',\n",
    "    #                     help='learning rate decay')\n",
    "    # parser.add_argument('-betas', default='0.99,0.999',\n",
    "    #                     help='beta for adam')\n",
    "    # parser.add_argument('-wd', type=float, default=5e-6,\n",
    "    #                     help='weight decay')\n",
    "    parser.add_argument('--volume-total', type=int, default=1000,\n",
    "                        help='Total number of iteration')\n",
    "    parser.add_argument('--volume-save', type=int, default=100,\n",
    "                        help='Number of iteration to save')\n",
    "    parser.add_argument('-g','--num-gpu', type=int,  default=1,\n",
    "                        help='Number of gpu')\n",
    "    parser.add_argument('-c','--num-cpu', type=int,  default=1,\n",
    "                        help='Number of cpu')\n",
    "    parser.add_argument('-b','--batch-size', type=int,  default=2,\n",
    "                        help='Batch size')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_args().batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init(args):\n",
    "    sn = args.output+'/'\n",
    "    if not os.path.isdir(sn):\n",
    "        os.makedirs(sn)\n",
    "    # I/O size in (z,y,x), no specified channel number\n",
    "    model_io_size = np.array([int(x) for x in args.model_input.split(',')])\n",
    "\n",
    "    # select training machine\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return model_io_size, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "model_io_size, device = init(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input(args, model_io_size, opt='train',zlayerdown=14,zlayerup=-14,imgsize=200):\n",
    "    # two dataLoader, can't be both multiple-cpu (pytorch issue)\n",
    "\n",
    "    if opt=='train':\n",
    "        dir_name = args.train.split('@')\n",
    "        num_worker = args.num_cpu\n",
    "        img_name = args.img_name.split('@')\n",
    "        seg_name = args.seg_name.split('@')\n",
    "    else:\n",
    "        dir_name = args.val.split('@')\n",
    "        num_worker = 1\n",
    "        img_name = args.img_name_val.split('@')\n",
    "        seg_name = args.seg_name_val.split('@')\n",
    "\n",
    "    # may use datasets from multiple folders\n",
    "    # should be either one or the same as dir_name\n",
    "    seg_name = [dir_name[0] + x for x in seg_name]\n",
    "    img_name = [dir_name[0] + x for x in img_name]\n",
    "    # print(img_name)\n",
    "    # print(seg_name)\n",
    "    \n",
    "    # 1. load data\n",
    "    train_input = [None]*len(img_name)\n",
    "    train_label = [None]*len(seg_name)\n",
    "    assert len(img_name)==len(seg_name)\n",
    "\n",
    "    # original image is in [0, 255], normalize to [0, 1]\n",
    "    for i in range(len(img_name)):\n",
    "        train_input[i] = np.array(h5py.File(img_name[i], 'r')['main'])[zlayerdown:zlayerup, imgsize:-imgsize, imgsize:-imgsize]/255.0\n",
    "        train_label[i] = np.array(h5py.File(seg_name[i], 'r')['main'])[zlayerdown:zlayerup, imgsize:-imgsize, imgsize:-imgsize]\n",
    "        train_label[i] = (train_label[i] != 0).astype(float)\n",
    "        assert train_input[i].shape==train_label[i].shape\n",
    "        print(\"volume shape: \", train_input[i].shape)    \n",
    "\n",
    "    dataset = SynapseDataset(volume=train_input, label=train_label, vol_input_size=model_io_size, \\\n",
    "                                 vol_label_size=model_io_size, data_aug=None) # no data augmentation\n",
    "    # to have evaluation during training (two dataloader), has to set num_worker=0\n",
    "    SHUFFLE = (opt=='train')\n",
    "    img_loader =  torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=args.batch_size, shuffle=SHUFFLE, collate_fn = collate_fn,\n",
    "            num_workers=args.num_cpu, pin_memory=True)\n",
    "    print (args.batch_size)\n",
    "    return img_loader,img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volume shape: ', (16, 479, 385))\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fc20b54ab90>,\n",
       " ['data/im_uint8.h5'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_input(get_args(), init(get_args())[0],'train',zlayerdown=14,zlayerup=30,imgsize=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 479, 385)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(h5py.File('data/im_uint8.h5', 'r')['main'])[14:30,600:-600,600:-600].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volume shape: ', (16, 1279, 1185))\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_input(get_args(), model_io_size, opt='train',zlayerdown=14,zlayerup=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_logger(args):\n",
    "    log_name = args.output+'/log'\n",
    "    date = str(datetime.datetime.now()).split(' ')[0]\n",
    "    time = str(datetime.datetime.now()).split(' ')[1].split('.')[0]\n",
    "    log_name += '_approx_'+date+'_'+time\n",
    "    logger = open(log_name+'.txt','w') # unbuffered, write instantly\n",
    "\n",
    "    # tensorboardX\n",
    "    writer = SummaryWriter('runs/'+log_name)\n",
    "    return logger, writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "logger, writer = get_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = res_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, device, criterion, optimizer, logger, writer):\n",
    "    # switch to train mode\n",
    "    print('start training iter')\n",
    "    model.train()\n",
    "    print('start training iter1')\n",
    "    volume_id = 0\n",
    "    \n",
    "    for i, (volume, label, class_weight, weight_factor) in enumerate(train_loader):\n",
    "        print('start training iter2')\n",
    "        volume_id += args.batch_size\n",
    "        print('start training iter3')\n",
    "        \n",
    "        # for gpu computing\n",
    "        print(weight_factor)\n",
    "        volume, label = volume.to(device), label.to(device)\n",
    "        class_weight = class_weight.to(device)\n",
    "        output = model(volume)\n",
    "        loss = criterion(output, label, class_weight)\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logger.write(\"[Volume %d] train_loss=%0.4f lr=%.5f\" % (volume_id, \\\n",
    "                loss.item(), optimizer.param_groups[0]['lr']))\n",
    "        writer.add_scalar('train_loss', loss.item(), volume_id)\n",
    "\n",
    "        # LR update\n",
    "        #if args.lr > 0:\n",
    "            #decay_lr(optimizer, args.lr, volume_id, lr_decay[0], lr_decay[1], lr_decay[2])\n",
    "        \n",
    "        if volume_id % args.volume_save < args.batch_size or volume_id >= args.volume_total:\n",
    "            torch.save(model.state_dict(), args.output+('/volume_%d.pth' % (volume_id)))\n",
    "        # Terminate\n",
    "        if volume_id >= args.volume_total:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('volume shape: ', (1, 179, 85))\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_input(get_args(), init(get_args())[0], 'train',zlayerdown=14,zlayerup=15,imgsize=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5425c505522d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_factor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m  \u001b[0;31m# ensure that the worker exits on process exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mforking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# reference to the process object (see bpo-30775)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'random'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "for i, (volume, label, class_weight, weight_factor) in enumerate(train_loader):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. initial setup\n",
      "1. setup data\n",
      "('volume shape: ', (1, 279, 185))\n",
      "2\n",
      "2. setup model\n",
      "3. setup optimizer\n",
      "4. start training\n",
      "start training iter\n",
      "start training iter1\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e558340c7d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-e558340c7d59>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4. start training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5. finish training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d08b61a3f07a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_loader, model, device, criterion, optimizer, logger, writer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvolume_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_factor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start training iter2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvolume_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m  \u001b[0;31m# ensure that the worker exits on process exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mforking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# reference to the process object (see bpo-30775)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chenxupeng/anaconda2/lib/python2.7/multiprocessing/forking.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'random'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args = get_args()\n",
    "\n",
    "    print('0. initial setup')\n",
    "    model_io_size, device = init(args) \n",
    "    logger, writer = get_logger(args)\n",
    "\n",
    "    print('1. setup data')\n",
    "    train_loader = get_input(args, model_io_size, 'train',zlayerdown=14,zlayerup=15,imgsize=700)\n",
    "    #train_loader = get_img(args, model_io_size, opt='train')\n",
    "    \n",
    "    print('2. setup model')\n",
    "    model = res_unet()\n",
    "    if args.finetune == True:\n",
    "        model.load_state_dict(torch.load(args.pre_model))\n",
    "        print('fine-tune on previous model')\n",
    "            \n",
    "    if args.num_gpu>1: model = nn.DataParallel(model, range(args.num_gpu))\n",
    "    model = model.to(device)\n",
    "    criterion = WeightedBCELoss()\n",
    "\n",
    "    print('3. setup optimizer')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "\n",
    "    print('4. start training')\n",
    "    \n",
    "    train(args, train_loader, model, device, criterion, optimizer, logger, writer)\n",
    "  \n",
    "    print('5. finish training')\n",
    "    logger.close()\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dinknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by calling partial(sum2, 4) you create a new function (a callable, to be precise) that behaves like sum2, but has one positional argument less. That missing argument is always substituted by 4, so that partial(sum2, 4)(2) == sum2(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://mp.weixin.qq.com/s/jpfvRbmTgFVQczHzKekmLw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据扩增-图像形态变换：\n",
    "\n",
    "①、随机翻折：包含水平、竖直、对角线三种翻折方式，每张图片扩增为原来的8倍。\n",
    "\n",
    "②、随机缩放：将图像随机缩放至多10%。\n",
    "\n",
    "③、随机偏移：将图像随机上下左右偏移至多10%。\n",
    "\n",
    "④、随机拉升：将图像随机沿竖直方向或水平方向拉升至多10%。\n",
    "\n",
    "经过以上四种变换之后，再截取图像中心1024*1024的部分，不足的部分补0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D-LinkNet使用LinkNet作为基本骨架，使用在ImageNet数据集上与训练好的ResNet作为网络的encoder，<br>\n",
    "并在中心部分添加带有shortcut的dilated-convolution层，使得整个网络识别能力更强、接收域更大、融合多尺度信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数的公式如下所示。损失函数包含两部分，其中红框部分是dice coeff loss，绿框部分是Binary cross entropy loss。<br>\n",
    "公式中P指代网络输出的预测结果，GT指代真实标签，N指代batchsize。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "nonlinearity = partial(F.relu,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dblock_more_dilate(nn.Module):\n",
    "    def __init__(self,channel):\n",
    "        super(Dblock_more_dilate, self).__init__()\n",
    "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilate2 = nn.Conv2d(channel, channel, kernel_size=3, dilation=2, padding=2)\n",
    "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=4, padding=4)\n",
    "        self.dilate4 = nn.Conv2d(channel, channel, kernel_size=3, dilation=8, padding=8)\n",
    "        self.dilate5 = nn.Conv2d(channel, channel, kernel_size=3, dilation=16, padding=16)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.dilate1(x))\n",
    "        dilate2_out = nonlinearity(self.dilate2(dilate1_out))\n",
    "        dilate3_out = nonlinearity(self.dilate3(dilate2_out))\n",
    "        dilate4_out = nonlinearity(self.dilate4(dilate3_out))\n",
    "        dilate5_out = nonlinearity(self.dilate5(dilate4_out))\n",
    "        out = x + dilate1_out + dilate2_out + dilate3_out + dilate4_out + dilate5_out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dblock(nn.Module):\n",
    "    def __init__(self,channel):\n",
    "        super(Dblock, self).__init__()\n",
    "        self.dilate1 = nn.Conv2d(channel, channel, kernel_size=3, dilation=1, padding=1)\n",
    "        self.dilate2 = nn.Conv2d(channel, channel, kernel_size=3, dilation=2, padding=2)\n",
    "        self.dilate3 = nn.Conv2d(channel, channel, kernel_size=3, dilation=4, padding=4)\n",
    "        self.dilate4 = nn.Conv2d(channel, channel, kernel_size=3, dilation=8, padding=8)\n",
    "        #self.dilate5 = nn.Conv2d(channel, channel, kernel_size=3, dilation=16, padding=16)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        dilate1_out = nonlinearity(self.dilate1(x))\n",
    "        dilate2_out = nonlinearity(self.dilate2(dilate1_out))\n",
    "        dilate3_out = nonlinearity(self.dilate3(dilate2_out))\n",
    "        dilate4_out = nonlinearity(self.dilate4(dilate3_out))\n",
    "        #dilate5_out = nonlinearity(self.dilate5(dilate4_out))\n",
    "        out = x + dilate1_out + dilate2_out + dilate3_out + dilate4_out# + dilate5_out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, n_filters):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu1 = nonlinearity\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(in_channels // 4)\n",
    "        self.relu2 = nonlinearity\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
    "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
    "        self.relu3 = nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DinkNet34_less_pool(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(DinkNet34_more_dilate, self).__init__()\n",
    "\n",
    "        filters = [64, 128, 256, 512]\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        \n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        \n",
    "        self.dblock = Dblock_more_dilate(256)\n",
    "\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        \n",
    "        #Center\n",
    "        e3 = self.dblock(e3)\n",
    "\n",
    "        # Decoder\n",
    "        d3 = self.decoder3(e3) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "\n",
    "        # Final Classification\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DinkNet34(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_channels=3):\n",
    "        super(DinkNet34, self).__init__()\n",
    "\n",
    "        filters = [64, 128, 256, 512]\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "        \n",
    "        self.dblock = Dblock(512)\n",
    "\n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        \n",
    "        # Center\n",
    "        e4 = self.dblock(e4)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        \n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DinkNet50(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(DinkNet50, self).__init__()\n",
    "\n",
    "        filters = [256, 512, 1024, 2048]\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "        \n",
    "        self.dblock = Dblock_more_dilate(2048)\n",
    "\n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        \n",
    "        # Center\n",
    "        e4 = self.dblock(e4)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DinkNet101(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(DinkNet101, self).__init__()\n",
    "\n",
    "        filters = [256, 512, 1024, 2048]\n",
    "        resnet = models.resnet101(pretrained=True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "        \n",
    "        self.dblock = Dblock_more_dilate(2048)\n",
    "\n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        \n",
    "        # Center\n",
    "        e4 = self.dblock(e4)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinkNet34(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LinkNet34, self).__init__()\n",
    "\n",
    "        filters = [64, 128, 256, 512]\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.firstconv = resnet.conv1\n",
    "        self.firstbn = resnet.bn1\n",
    "        self.firstrelu = resnet.relu\n",
    "        self.firstmaxpool = resnet.maxpool\n",
    "        self.encoder1 = resnet.layer1\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "\n",
    "        self.decoder4 = DecoderBlock(filters[3], filters[2])\n",
    "        self.decoder3 = DecoderBlock(filters[2], filters[1])\n",
    "        self.decoder2 = DecoderBlock(filters[1], filters[0])\n",
    "        self.decoder1 = DecoderBlock(filters[0], filters[0])\n",
    "\n",
    "        self.finaldeconv1 = nn.ConvTranspose2d(filters[0], 32, 3, stride=2)\n",
    "        self.finalrelu1 = nonlinearity\n",
    "        self.finalconv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.finalrelu2 = nonlinearity\n",
    "        self.finalconv3 = nn.Conv2d(32, num_classes, 2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.firstconv(x)\n",
    "        x = self.firstbn(x)\n",
    "        x = self.firstrelu(x)\n",
    "        x = self.firstmaxpool(x)\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.decoder4(e4) + e3\n",
    "        d3 = self.decoder3(d4) + e2\n",
    "        d2 = self.decoder2(d3) + e1\n",
    "        d1 = self.decoder1(d2)\n",
    "        out = self.finaldeconv1(d1)\n",
    "        out = self.finalrelu1(out)\n",
    "        out = self.finalconv2(out)\n",
    "        out = self.finalrelu2(out)\n",
    "        out = self.finalconv3(out)\n",
    "\n",
    "        return F.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
